
# Autogenerated using jinja files
from quixstreams import Application
from quixstreams.kafka import ConnectionConfig 
from beaver.pipeline import *
from dash import Dash
from dash.dependencies import Input, Output
from dash import dcc, html
import plotly.graph_objs as go
import threading
from plotly.subplots import make_subplots


    
from river import neural_net
    
from river import optim
from river import preprocessing
from river import metrics




ReLU = neural_net.activations.ReLU(
)
Identity = neural_net.activations.Identity(
)
SGDopt = optim.SGD(
    lr = 0.001
)
neural = neural_net.MLPRegressor(
    hidden_dims = (5,),
    activations = (ReLU,ReLU,Identity),
    optimizer = SGDopt,
    seed = 42
)
StandardScaler = preprocessing.StandardScaler(
)
mae = metrics.MAE(
)



#Define connection
connectionConfig = ConnectionConfig(
    bootstrap_servers = 'localhost:39092',
    security_protocol = 'plaintext',
)

#Connection to Kafka
app = Application( 
    broker_address = connectionConfig,
    consumer_group = 'neighbours_models',
    auto_offset_reset = 'earliest',
)

#Input topics 

input_topic_TrumpApproval = app.topic("TrumpApproval", value_deserializer="json")

# Create Streaming DataFrames connected to the input Kafka topics

sdf_TrumpApproval = app.dataframe(topic=input_topic_TrumpApproval)

#Drop Features


#Keep Features




#Connect composers with preprocessors 

preprocessor_TrumpApproval =StandardScaler



#Pipeline definition 

neuralPipeline_pipeline = preprocessor_TrumpApproval |neural
neuralPipeline_metrics = [mae]


neuralPipeline = Pipeline(model = neuralPipeline_pipeline, model_name ='MLPRegressor'  , metrics_list = neuralPipeline_metrics , name = "neuralPipeline",y="five_thirty_eight",output_topic="neuralPipeline")



# Output topics initialization

output_topic_neuralPipeline = app.topic(neuralPipeline.output_topic, value_deserializer="json")



#Sdf for each pipeline 
#Train and predict method calls for each pipeline
#If the pipeline has an output topic then we call it 

sdf_neuralPipeline = sdf_TrumpApproval.apply(neuralPipeline.train_and_predict).to_topic(output_topic_neuralPipeline)


# ---------- DASHBOARD SETUP ----------

def run_dash():
    dash_app = Dash(__name__)
    dash_app.layout = html.Div([
         html.H2("Pipelines' Plots" , style={
        'textAlign': 'center',  # Center the text

        'fontFamily': 'sans-serif',  # Change the font family
        'font-weight': 'normal',  # Make the text bold
        }),
        dcc.Interval(id='interval', n_intervals=0),
        dcc.Graph(id='live-graph'), 
        html.Div(
            children=[
                
                dcc.Graph(
                    id='live-stats-neuralPipeline',
                    #style={'margin': 'auto', 'display': 'block', 'width':'70%'}
                )
            ]
        )
    ])

    @dash_app.callback(
        Output('live-graph', 'figure'),
        Input('interval', 'n_intervals')
    )
    def update_graph(n):
        fig = make_subplots(rows=1, cols=1 , vertical_spacing=0.1)

        
        neuralPipeline.add_metrics_traces(fig = fig , row = 1, col = 1 ) 
        

        fig.update_layout(height=600, title="Live Metrics", margin=dict(t=40, b=40), showlegend=True )
        return fig


    
    @dash_app.callback(
        Output(
            component_id='live-stats-neuralPipeline', 
            component_property='figure'
        ), 
        Input(
            component_id='interval', 
            component_property='n_intervals'
        )
    )

      
    def update_stats_neuralPipeline(n):
        
        traces = []  
        
        neuralPipeline.add_stats_traces(traces) 
              

        
        if traces:
            fig = go.Figure(
                    data=traces, 
                    layout= go.Layout(
                        title='neuralPipeline Statistics'
                    )
            )
            return fig    
    
        return go.Figure()
    
    dash_app.run(debug=False, use_reloader=False)

if __name__ == '__main__':
    #Run Plotly on different thread
    threading.Thread(target=run_dash, daemon=True).start()
   
    # Run Quix Streams 
    app.run()