
# Autogenerated using jinja files
from quixstreams import Application
from quixstreams.kafka import ConnectionConfig 
from beaver.pipeline import *
from dash import Dash
from dash.dependencies import Input, Output
from dash import dcc, html
import plotly.graph_objs as go
import threading
from plotly.subplots import make_subplots


from river import neighbors
from river import forest
from river import optim
from river import linear_model
from river import compose
from river import metrics
from river import preprocessing




knn = neighbors.KNNClassifier(
)
amf = forest.AMFClassifier(
    n_estimators =10,
    use_aggregation =True,
    dirichlet =0.5,
    seed =1
)
sgd = optim.SGD(
    lr =0.1
)
logistic = linear_model.LogisticRegression(
    optimizer =sgd
)
select = compose.SelectType((int,float)
)
selectstr = compose.SelectType(str
)
accuracy = metrics.Accuracy(
)
recall = metrics.Recall(
)
roc = metrics.ROCAUC(
)
encoder = preprocessing.OneHotEncoder(
)
scaler = preprocessing.StandardScaler(
)



#Define connection
connectionConfig = ConnectionConfig(
    bootstrap_servers = 'localhost:39092',
    security_protocol = 'plaintext',
)

#Connection to Kafka
app = Application( 
    broker_address = connectionConfig,
    consumer_group = 'heart-failure',
    auto_offset_reset = 'earliest',
)

#Input topics 

input_topic_Heart_Failure_Prediction = app.topic("Heart_Failure_Prediction", value_deserializer="json")

# Create Streaming DataFrames connected to the input Kafka topics

sdf_Heart_Failure_Prediction = app.dataframe(topic=input_topic_Heart_Failure_Prediction)

#Drop Features


#Keep Features




#Connect composers with preprocessors 

preprocessor_Heart_Failure_Prediction =((select|scaler)+(selectstr|encoder))



#Pipeline definition 

KNNClassifierPipeline_pipeline = preprocessor_Heart_Failure_Prediction |knn
KNNClassifierPipeline_metrics = [accuracy,recall,roc]


KNNClassifierPipeline = Pipeline(model = KNNClassifierPipeline_pipeline, model_name ='KNNClassifier'  , metrics_list = KNNClassifierPipeline_metrics , name = "KNNClassifierPipeline",y="HeartDisease",output_topic="KNNClassifierPipeline")

amfClassifierPipeline_pipeline = preprocessor_Heart_Failure_Prediction |amf
amfClassifierPipeline_metrics = [accuracy,recall,roc]


amfClassifierPipeline = Pipeline(model = amfClassifierPipeline_pipeline, model_name ='AMFClassifier'  , metrics_list = amfClassifierPipeline_metrics , name = "amfClassifierPipeline",y="HeartDisease",output_topic="amfClassifierPipeline")

logisticPipeline_pipeline = preprocessor_Heart_Failure_Prediction |logistic
logisticPipeline_metrics = [accuracy,recall,roc]


logisticPipeline = Pipeline(model = logisticPipeline_pipeline, model_name ='LogisticRegression'  , metrics_list = logisticPipeline_metrics , name = "logisticPipeline",y="HeartDisease",output_topic="logisticPipeline")



# Output topics initialization

output_topic_KNNClassifierPipeline = app.topic(KNNClassifierPipeline.output_topic, value_deserializer="json")

output_topic_amfClassifierPipeline = app.topic(amfClassifierPipeline.output_topic, value_deserializer="json")

output_topic_logisticPipeline = app.topic(logisticPipeline.output_topic, value_deserializer="json")



#Sdf for each pipeline 
#Train and predict method calls for each pipeline
#If the pipeline has an output topic then we call it 

sdf_KNNClassifierPipeline = sdf_Heart_Failure_Prediction.apply(KNNClassifierPipeline.train_and_predict).to_topic(output_topic_KNNClassifierPipeline)
sdf_amfClassifierPipeline = sdf_Heart_Failure_Prediction.apply(amfClassifierPipeline.train_and_predict).to_topic(output_topic_amfClassifierPipeline)
sdf_logisticPipeline = sdf_Heart_Failure_Prediction.apply(logisticPipeline.train_and_predict).to_topic(output_topic_logisticPipeline)


# ---------- DASHBOARD SETUP ----------

def run_dash():
    dash_app = Dash(__name__)
    dash_app.layout = html.Div([
         html.H2("Pipelines' Plots" , style={
        'textAlign': 'center',  # Center the text

        'fontFamily': 'sans-serif',  # Change the font family
        'font-weight': 'normal',  # Make the text bold
        }),
        dcc.Interval(id='interval', n_intervals=0),
        dcc.Graph(id='live-graph'), 
        html.Div(
            children=[
                
                dcc.Graph(
                    id='live-stats-KNNClassifierPipeline',
                    #style={'margin': 'auto', 'display': 'block', 'width':'70%'}
                ),
                dcc.Graph(
                    id='live-stats-amfClassifierPipeline',
                    #style={'margin': 'auto', 'display': 'block', 'width':'70%'}
                ),
                dcc.Graph(
                    id='live-stats-logisticPipeline',
                    #style={'margin': 'auto', 'display': 'block', 'width':'70%'}
                )
            ]
        )
    ])

    @dash_app.callback(
        Output('live-graph', 'figure'),
        Input('interval', 'n_intervals')
    )
    def update_graph(n):
        fig = make_subplots(rows=3, cols=1 , vertical_spacing=0.1)

        
        KNNClassifierPipeline.add_metrics_traces(fig = fig , row = 1, col = 1 ) 
        
        amfClassifierPipeline.add_metrics_traces(fig = fig , row = 2, col = 1 ) 
        
        logisticPipeline.add_metrics_traces(fig = fig , row = 3, col = 1 ) 
        

        fig.update_layout(height=600, title="Live Metrics", margin=dict(t=40, b=40), showlegend=True )
        return fig


    
    @dash_app.callback(
        Output(
            component_id='live-stats-KNNClassifierPipeline', 
            component_property='figure'
        ), 
        Input(
            component_id='interval', 
            component_property='n_intervals'
        )
    )

      
    def update_stats_KNNClassifierPipeline(n):
        
        traces = []  
        
        KNNClassifierPipeline.add_stats_traces(traces) 
              

        
        if traces:
            fig = go.Figure(
                    data=traces, 
                    layout= go.Layout(
                        title='KNNClassifierPipeline Statistics'
                    )
            )
            return fig    
    
        return go.Figure()
    
    @dash_app.callback(
        Output(
            component_id='live-stats-amfClassifierPipeline', 
            component_property='figure'
        ), 
        Input(
            component_id='interval', 
            component_property='n_intervals'
        )
    )

      
    def update_stats_amfClassifierPipeline(n):
        
        traces = []  
        
        amfClassifierPipeline.add_stats_traces(traces) 
              

        
        if traces:
            fig = go.Figure(
                    data=traces, 
                    layout= go.Layout(
                        title='amfClassifierPipeline Statistics'
                    )
            )
            return fig    
    
        return go.Figure()
    
    @dash_app.callback(
        Output(
            component_id='live-stats-logisticPipeline', 
            component_property='figure'
        ), 
        Input(
            component_id='interval', 
            component_property='n_intervals'
        )
    )

      
    def update_stats_logisticPipeline(n):
        
        traces = []  
        
        logisticPipeline.add_stats_traces(traces) 
              

        
        if traces:
            fig = go.Figure(
                    data=traces, 
                    layout= go.Layout(
                        title='logisticPipeline Statistics'
                    )
            )
            return fig    
    
        return go.Figure()
    
    dash_app.run(debug=False, use_reloader=False)

if __name__ == '__main__':
    #Run Plotly on different thread
    threading.Thread(target=run_dash, daemon=True).start()
   
    # Run Quix Streams 
    app.run()