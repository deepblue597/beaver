# Autogenerated from python.template file

from quixstreams import Application
from quixstreams.models import TopicConfig
import seaborn as sns

from river import metrics , preprocessing
from river import {{pipeline.model.type}}
import matplotlib.pyplot as plt
from river import ensemble
from river import optim
from sklearn.metrics import confusion_matrix
from river import compose
from river import preprocessing
import json
{%if pipeline.model.multiclass-%}
from river import multiclass
{%-endif %}
import dill
import numpy as np 


# Define an application that will connect to Kafka
app = Application(
    broker_address="{{pipeline.kafka.broker}}",  # Kafka broker address
    auto_offset_reset="earliest",
    consumer_group="{{pipeline.kafka.consumer_group}}",
)

# Define the Kafka topics
input_topic = app.topic("{{pipeline.kafka.input_topic}}", value_deserializer="json")

{% if pipeline.kafka.output_topic -%}
output_topic = app.topic("{{pipeline.kafka.output_topic}}",
                        value_serializer="json")
{%-endif -%}
# Create a Streaming DataFrame connected to the input Kafka topic
sdf = app.dataframe(topic=input_topic)


{%if pipeline.model.preprocessors %}
#Define preprocessing  
{%- for  preprocessor in pipeline.model.preprocessors%}

preprocessor_{{loop.index0}} = {% if preprocessor.feature_type -%} 
    compose.SelectType({{preprocessor.feature_type}}) |
{%- endif -%}
preprocessing.{{preprocessor.name}}(
    {%- if preprocessor.params-%}
    {%- for param in preprocessor.params -%}
     {{ param.name }} = {{param.value.value}},
    {%endfor%}
    {%- endif -%}
)

{%- endfor %}
{%- endif %}

# Define River Model

{%-if pipeline.model.ensemble %}

model = ensemble.{{pipeline.model.ensemble.algorithm}}(
{%-endif%}
model =(
    {%-if pipeline.model.preprocessors %}
    (
    {% for  preprocessor in pipeline.model.preprocessors%}
    preprocessor_{{loop.index0}}
    {%- if not loop.last %} + 
    {%- endif -%} 
    {%endfor%})|
    {%- endif %}
    {% if pipeline.model.multiclass-%}
    multiclass.{{pipeline.model.multiclass.name}}(
    {%- endif %}
    {{pipeline.model.type}}.{{pipeline.model.name}}(

    {%-if pipeline.model.splitter-%}
    feature_quantizer=tree.splitter.{{pipeline.model.splitter.name}}(
            {%-for param in pipeline.model.splitter.params %}
            {{ param.name }} = {{param.value.value}}, 
            {%-endfor%}
    ),
    {%-endif%}

    {%-if pipeline.model.optimizer-%}
        optim.{{pipeline.model.optimizer.name}}(
            {%-for param in pipeline.model.optimizer.params %}
            {{ param.name }} = {{param.value.value}}, 
            {%-endfor%}
            ),
    {%-endif%}
    {% for param in pipeline.model.params %}
        {{ param.name }} = {{param.value.value}}, 

    {%- endfor %}

    )
    {%- if pipeline.model.multiclass-%}
    ,{% for param in pipeline.model.multiclass.params %}
        {{ param.name }} = {{param.value.value}},
     
    {%- endfor %}
    {% if pipeline.model.multiclass.coding_method%}
        coding_method = "{{pipeline.model.multiclass.coding_method}}"
    )
    {%-endif-%}
    {%- endif -%}
)
    {%if pipeline.model.ensemble %}
    ,n_models =  {{pipeline.model.ensemble.num}}, 
    seed= {{pipeline.model.ensemble.seed}}
)
    {%-endif%}


# Define new features
{%for assignment in assignments -%}

{% if assignment == ';' %}
{% elif assignment == '(' or assignment == ')' -%}
    {{ assignment }}
{%- elif assignment is number -%}
    {{ assignment }}
{%- elif assignment in ['+', '-', '*', '/', '='] -%}
    {{ assignment }}
{%- else -%}
    sdf["{{ assignment }}"]
{%- endif %}
{%-endfor%}

# Drop features 
{% if pipeline.features.features%}
sdf.drop([
    {%- for feature  in pipeline.features.features -%}
    "{{feature}}"
    {%- if not loop.last %},
    {%- endif -%} 
    {%- endfor -%}
])
{%endif%}

# Define metrics
metric = {% for metric in pipeline.metrics.metrics -%}  
metrics.{{metric}}() 
{%- if not loop.last %} + 
{%- endif -%} 
{% endfor %} 
   
{% for metric in pipeline.metrics.metrics -%}  
{{metric}} = [] 
{% endfor %} 


{%if pipeline.target.mappings %}
# Define target mapping
target_mapping = {
    {% for mapping in pipeline.target.mappings -%}
    "{{ mapping.key }}": {{ mapping.value }},
    {% endfor %}
}
{% endif %}


{% if pipeline.plot %}
# Variables for plotting
{% if pipeline.plot.x_axis -%}
x_axis = []
{% endif %}
{%- if pipeline.plot.y_axis-%}
y_axis = []
{% endif %}
y_true = []
y_pred = []
{% endif %}

# Function for training the model
def train_and_predict(X):


    {% if pipeline.target %}
    X = {key: value for key, value in X.items() if key != "{{ pipeline.target.name }}"}  
    {% endif %}
    {% if pipeline.target.mappings %}
    y = target_mapping[X["{{ pipeline.target.name }}"]]
    {% elif pipeline.target %}
    y = X["{{ pipeline.target.name }}"]
    {% endif %} 
    {% if pipeline.target %}
    model.learn_one(X, y)
    {% else %}
    model.learn_one(X)
    {% endif %} 
    
    {% if pipeline.model.proba -%}
    y_predicted = model.predict_proba_one(X)
    {%- else%}
    y_predicted = model.predict_one(X)
    {%- endif %}
    
    
    # Update metric
    {%if pipeline.model.type == 'cluster' -%}
    metric.update(X, y_predicted,  model.centers) 
    {%-else %}
    metric.update(y, y_predicted )
    {%-endif%}

    {% if pipeline.target %}
    print(f"True y: {y}, Predicted: {y_predicted}")
    {% endif %}
    print(metric)
    {%-if pipeline.metrics.metrics|length > 1%}
    {% for metric in pipeline.metrics.metrics -%}  
    {{metric}}.append(metric.get()[{{loop.index0}}])
    {% endfor %} 
    {%else%}
    {{pipeline.metrics.metrics[0]}}.append(metric.get()) 
    {%endif%}
    


    with open('{{pipeline.model.name}}.pkl', 'wb') as model_file:
        dill.dump(model, model_file)

    {% if pipeline.plot %}
    {%- if pipeline.plot.x_axis -%}
    x_axis.append(X["{{pipeline.plot.x_axis}}"])
    {%- endif %}
    {% if pipeline.plot.y_axis -%}
    y_axis.append(X["{{pipeline.plot.y_axis}}"])
    {%- endif %}



    # in some cases model returns one (e.g first learn one iteration in OneVsOneClassifier)
    # so we check if y_pred is not None to add to the lists
    if y_predicted is not None:
        {% if pipeline.target.mappings -%}
        y_true.append(y)
        {%- endif %}
        y_pred.append({%-if pipeline.model.proba-%}
                        max(y_predicted, key=y_predicted.get)
                        {%-else-%}y_predicted
                        {%-endif-%}
                    )
        {% endif %}


    return {% if pipeline.kafka.output_topic -%}
            {
                **X, 
                {% if pipeline.model.proba -%}
                "predicted probabilities": json.dumps(y_predicted) , 
                {%- else%}
                "Prediction": y_predicted,
                {%- endif %}   
                {%-if pipeline.metrics.metrics|length > 1-%}
                {% for metric in pipeline.metrics.metrics %}  
                "{{metric}}": metric.get()[{{loop.index0}}]
                {%- if not loop.last %} ,
                {%- endif -%} 
                {% endfor %} 
                {%else%}
                "{{pipeline.metrics.metrics[0]}}": metric.get()
                {%endif%}
            }   

            {%- else -%}
            X
            {%- endif %}


# Apply the train_and_predict function to each row in the filtered DataFrame
sdf = sdf.apply(train_and_predict)

{%if pipeline.kafka.output_topic -%}
# Output topic 
sdf = sdf.to_topic(output_topic)
{%-endif-%}
# Run the streaming application (app automatically tracks the sdf!)
app.run()

{% if pipeline.plot.type == 'graph' %}
# Plot the data
plt.figure(figsize=(10, 5))
plt.plot(x_axis, y_true, label='y')
plt.plot(x_axis, y_pred, label='Predicted y', linestyle='--')
plt.xlabel("{{pipeline.plot.x_axis}}")
plt.ylabel("{{ pipeline.target.name }}")
plt.title("{{ pipeline.target.name }} over  {{pipeline.plot.x_axis}} ")
plt.legend()
plt.show()

{%elif pipeline.plot.type == 'scatter' %}

plt.figure(figsize=(8, 6))
plt.scatter(y_true, y_pred, alpha=0.5)
plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--')  # Ideal line
plt.xlabel("Real Values {{(pipeline.target.name)}}")
plt.ylabel("Predicted Values {{pipeline.target.name}} ")
plt.title("Real vs Predicted {{pipeline.target.name}}")
plt.show()

{%elif pipeline.plot.type == 'heatmap'%}

# Generate the confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Create a heatmap of the confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix Heatmap')
plt.show()

{%elif pipeline.plot.type == 'cluster'%}
centers = np.array([list(model.centers[i].values()) for i in model.centers])
x_axis = np.array(x_axis)
y_axis = np.array(y_axis)
center_colors = [plt.cm.viridis(i / (len(centers) - 1))
                 for i in range(len(centers))]

# Scatter plot: Data points with cluster colors
plt.scatter(x_axis, y_axis, c=y_pred,
            cmap="viridis", alpha=0.6, edgecolors="k", label="Points")


for i, center in enumerate(centers):
    plt.scatter(center[0], center[1], c=[center_colors[i]],
                marker='x', s=200, label=f"Cluster {i} Center")
plt.title('Cluster Centers')
plt.xlabel("{{pipeline.plot.x_axis}}")
plt.ylabel("{{pipeline.plot.y_axis}}")
plt.legend()
plt.show()

{% endif %}


{% for metric in pipeline.metrics.metrics -%}  
plt.plot({{metric}})
plt.xlabel('Iterations')
plt.ylabel('{{metric}}')
plt.title('{{metric}} over Training Iterations')
plt.show()
{% endfor %} 
