# Autogenerated from python.template file

from quixstreams import Application
from quixstreams.models import TopicConfig
from river.datasets import synth
from river import evaluate
from river import metrics , preprocessing
from river import tree
import dill

# A minimal application reading temperature data in Celsius from the Kafka topic,
# converting it to Fahrenheit and producing alerts to another topic.

# Define an application that will connect to Kafka
app = Application(
    broker_address="{{pipeline.kafka.broker}}",  # Kafka broker address
    auto_offset_reset="earliest",
    consumer_group="{{pipeline.kafka.consumer_group}}",
)

# Define the Kafka topics
input_topic = app.topic("{{pipeline.kafka.input_topic}}", value_deserializer="json")
output_topic = app.topic("{{pipeline.kafka.output_topic}}",
                        value_serializer="json")
# Create a Streaming DataFrame connected to the input Kafka topic
sdf = app.dataframe(topic=input_topic)


model =(
    {%if pipeline.model.preprocessing %}
    
    preprocessing.{{ pipeline.model.preprocessing.name }}()|
    
     {% endif %}
    {{pipeline.model.name}}(
    {% for param in pipeline.model.params %}

        {{ param.name }} = {{param.value}}, 

    {% endfor %}
)
)

metric = metrics.MAE()

# Define target mapping
target_mapping = {
    {% for mapping in pipeline.target.mappings %}
    "{{ mapping.key }}": {{ mapping.value }},
    {% endfor %}
}

def train_and_predict(event):

    X = { 
        {% for feature in pipeline.features.features %}
        "{{feature}}": event["{{feature}}"],
        {% endfor %}
    }
    y = target_mapping[event["{{ pipeline.target.name }}"]]

    model.learn_one(X, y)

    predicted_class = model.predict_one(X)
    

    # Update accuracy metric
    metric.update(y, predicted_class)

    print(f"True Label: {y}, Predicted: {predicted_class}")
    print(f"Current Accuracy: {metric}")

    with open('{{pipeline.model.name}}.pkl', 'wb') as model_file:
        dill.dump(model, model_file)

    return event


# Apply the train_and_predict function to each row in the filtered DataFrame
sdf = sdf.apply(train_and_predict)


sdf = sdf.to_topic(output_topic)

# Run the streaming application (app automatically tracks the sdf!)
app.run()
