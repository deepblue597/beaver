# Autogenerated from python.template file

from quixstreams import Application
from quixstreams.models import TopicConfig

from river import metrics , preprocessing
from river import {{pipeline.model.type}}
import matplotlib.pyplot as plt


import dill

# A minimal application reading temperature data in Celsius from the Kafka topic,
# converting it to Fahrenheit and producing alerts to another topic.

# Define an application that will connect to Kafka
app = Application(
    broker_address="{{pipeline.kafka.broker}}",  # Kafka broker address
    auto_offset_reset="earliest",
    consumer_group="{{pipeline.kafka.consumer_group}}",
)

# Define the Kafka topics
input_topic = app.topic("{{pipeline.kafka.input_topic}}", value_deserializer="json")
output_topic = app.topic("{{pipeline.kafka.output_topic}}",
                        value_serializer="json")
# Create a Streaming DataFrame connected to the input Kafka topic
sdf = app.dataframe(topic=input_topic)


model =(
    {%if pipeline.model.preprocessing %}
    
    preprocessing.{{ pipeline.model.preprocessing }}()|
    
     {% endif %}
    {{pipeline.model.type}}.{{pipeline.model.name}}(
    {% for param in pipeline.model.params %}
        {{ param.name }} = {{param.value.value}}, 
    {% endfor %}
)
)

metric = {% for metric in pipeline.metrics.metrics %}  metrics.{{metric}}() {% if not loop.last %} + {% endif %} {% endfor %} 
   



# Define target mapping
{%if pipeline.target.mappings %}
target_mapping = {
    {% for mapping in pipeline.target.mappings %}
    "{{ mapping.key }}": {{ mapping.value }},
    {% endfor %}
}
{% endif %}
{% if pipeline.plot %}
x_axis = []
y_true = []
y_pred = []
{% endif %}
def train_and_predict(event):

    X = { 
        {% for feature in pipeline.features.features %}
        "{{feature}}": event["{{feature}}"],
        {% endfor %}
    }

    {% if pipeline.target.mappings %}
    y = target_mapping[event["{{ pipeline.target.name }}"]]
    {% elif pipeline.target %}
    y = event["{{ pipeline.target.name }}"]
    {% endif %} 
    {% if pipeline.target %}
    model.learn_one(X, y)
    {% else %}
    model.learn_one(X)
    {% endif %} 
    
    y_predicted = model.predict_one(X)
    

    # Update accuracy metric
    metric.update(y, y_predicted)
    {% if pipeline.target.mappings %}
    print(f"True Label: {y}, Predicted: {y_predicted}")
    {% endif %}
    print(metric)

    with open('{{pipeline.model.name}}.pkl', 'wb') as model_file:
        dill.dump(model, model_file)

    {% if pipeline.plot %}
    x_axis.append(event["{{pipeline.plot.x_axis}}"])
    y_true.append(y)
    y_pred.append(y_predicted)
    {% endif %}


    return event


# Apply the train_and_predict function to each row in the filtered DataFrame
sdf = sdf.apply(train_and_predict)


sdf = sdf.to_topic(output_topic)

# Run the streaming application (app automatically tracks the sdf!)
app.run()

{% if pipeline.plot %}
# Plot the data
plt.figure(figsize=(10, 5))
plt.plot(x_axis, y_true, label='y')
plt.plot(x_axis, y_pred, label='Predicted y', linestyle='--')
plt.xlabel("{{pipeline.plot.x_axis}}")
plt.ylabel("{{ pipeline.target.name }}")
plt.title("{{ pipeline.target.name }} over  {{pipeline.plot.x_axis}} ")
plt.legend()
plt.show()
{% endif %}
