# Autogenerated from python.template file

from quixstreams import Application
from quixstreams.models import TopicConfig
import seaborn as sns

from river import metrics, preprocessing
from river import linear_model
import matplotlib.pyplot as plt
from river import ensemble
from river import optim
from sklearn.metrics import confusion_matrix

import dill


# Define an application that will connect to Kafka
app = Application(
    broker_address="localhost:39092",  # Kafka broker address
    auto_offset_reset="earliest",
    consumer_group="wikipedia-model-2",
)

# Define the Kafka topics
input_topic = app.topic("wikipedia-events", value_deserializer="json")

output_topic = app.topic("filtered-wikipedia-events",
                         # Create a Streaming DataFrame connected to the input Kafka topic
                         value_serializer="json")
sdf = app.dataframe(topic=input_topic)

# Define River Model
model = (

    preprocessing.OrdinalEncoder() |
    linear_model.LogisticRegression(optim.Adam()


                                    )
)


# Define new features
sdf["len_diff"] = ((sdf["new_length"])-(sdf["old_length"]))


# Define metrics
metric = metrics.MAE()

MAE = []


# Define target mapping
target_mapping = {
    "bot": 1,
    "human": 0,

}


# Variables for plotting
y_true = []
y_pred = []


# Function for training the model
def train_and_predict(event):

    X = {
        "domain": event["domain"],
        "namespace": event["namespace"],
        "title": event["title"],
        "comment": event["comment"],
        "user_name": event["user_name"],
        "new_length": event["new_length"],
        "old_length": event["old_length"],
        "minor": event["minor"],
        "len_diff": event["len_diff"],

    }

    y = target_mapping[event["user_type"]]

    model.learn_one(X, y)

    y_predicted = model.predict_one(X)

    # Update accuracy metric
    metric.update(y, y_predicted)

    print(f"True Label: {y}, Predicted: {y_predicted}")

    print(metric)
    MAE.append(metric)

    with open('LogisticRegression.pkl', 'wb') as model_file:
        dill.dump(model, model_file)

    y_true.append(y)
    y_pred.append(y_predicted)

    return event


# Apply the train_and_predict function to each row in the filtered DataFrame
sdf = sdf.apply(train_and_predict)

# Output topic
# Run the streaming application (app automatically tracks the sdf!)
sdf = sdf.to_topic(output_topic)
app.run()


# Generate the confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Create a heatmap of the confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[
            'Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix Heatmap')
plt.show()


plt.plot(MAE)
plt.xlabel('Iterations')
plt.ylabel('MAE')
plt.title('MAE over Training Iterations')
plt.show()
