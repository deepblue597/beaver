# Autogenerated from python.template file

from quixstreams import Application
from quixstreams.models import TopicConfig
from quixstreams.kafka import ConnectionConfig 
from pipeline import * 











from river import anomaly













#Define live data algorithms
HalfSpaceTrees = anomaly.HalfSpaceTrees(
    n_trees =5,
    height =3,
    window_size =3,
    seed =42)


#Connection Configuration for quixstreams
connectionConfig = ConnectionConfig( 
    
    bootstrap_servers ="localhost:39092",
    security_protocol ="plaintext")

#Connection to Kafka 
app = Application( 
    broker_address = connectionConfig,
    consumer_group ="anomaly",
    auto_offset_reset ="earliest")

#Input topics 

input_topic_anomaly = app.topic("anomaly_detection", value_deserializer="json")

# Create Streaming DataFrames connected to the input Kafka topics

sdf_anomaly = app.dataframe(topic=input_topic_anomaly)



#Connect composers with preprocessors 



#Pipeline definition 

HalfSpaceTreesPipe_pipeline =HalfSpaceTrees

HalfSpaceTreesPipe = Pipeline(model = HalfSpaceTreesPipe_pipeline , name = "HalfSpaceTreesPipe",output_topic="HalfSpaceTreesBVR")

# Output topics initialization

output_topic_HalfSpaceTreesPipe = app.topic(HalfSpaceTreesPipe.output_topic, value_deserializer="json")


#Sdf for each pipeline 
#Train and predict method calls for each pipeline
#If the pipeline has an output topic then we call it 

sdf_HalfSpaceTreesPipe = sdf_anomaly.apply(HalfSpaceTreesPipe.train_and_predict).to_topic(output_topic_HalfSpaceTreesPipe)


# Run Quix Streams 
app.run()

#Metric plots for each Pipeline

