
# Autogenerated using jinja files
from quixstreams import Application
from quixstreams.kafka import ConnectionConfig 
from pipeline import *
from dash import Dash
from dash.dependencies import Input, Output
from dash import dcc, html
import plotly.graph_objs as go
import threading
from plotly.subplots import make_subplots


from river import linear_model
from river import preprocessing
from river import metrics




alma = linear_model.ALMAClassifier(
)
linear = linear_model.LinearRegression(
    intercept_lr = 0.1
)
scaler = preprocessing.StandardScaler(
)
mae = metrics.MAE(
)
acc = metrics.Accuracy(
)



#Define connection
connectionConfig = ConnectionConfig(
    bootstrap_servers = 'localhost:39092',
    security_protocol = 'plaintext',
)

#Connection to Kafka
app = Application( 
    broker_address = connectionConfig,
    consumer_group = 'linear_models',
    auto_offset_reset = 'earliest',
)

#Input topics 

input_topic_Phishing = app.topic("Phishing", value_deserializer="json")
input_topic_TrumpApproval = app.topic("TrumpApproval", value_deserializer="json")

# Create Streaming DataFrames connected to the input Kafka topics

sdf_Phishing = app.dataframe(topic=input_topic_Phishing)
sdf_TrumpApproval = app.dataframe(topic=input_topic_TrumpApproval)

#Drop Features


#Keep Features




#Connect composers with preprocessors 

preprocessor_Phishing =scaler


preprocessor_TrumpApproval =scaler



#Pipeline definition 

almaPipeline_pipeline = preprocessor_Phishing |alma
almaPipeline_metrics = [acc]


almaPipeline = Pipeline(model = almaPipeline_pipeline, model_name ='ALMAClassifier'  , metrics_list = almaPipeline_metrics , name = "almaPipeline",y="is_phishing",output_topic="almaPipeline")

LinearRegressionPipeline_pipeline = preprocessor_TrumpApproval |linear
LinearRegressionPipeline_metrics = [mae]


LinearRegressionPipeline = Pipeline(model = LinearRegressionPipeline_pipeline, model_name ='LinearRegression'  , metrics_list = LinearRegressionPipeline_metrics , name = "LinearRegressionPipeline",y="five_thirty_eight",output_topic="LinearRegressionPipeline")



# Output topics initialization

output_topic_almaPipeline = app.topic(almaPipeline.output_topic, value_deserializer="json")

output_topic_LinearRegressionPipeline = app.topic(LinearRegressionPipeline.output_topic, value_deserializer="json")



#Sdf for each pipeline 
#Train and predict method calls for each pipeline
#If the pipeline has an output topic then we call it 

sdf_almaPipeline = sdf_Phishing.apply(almaPipeline.train_and_predict).to_topic(output_topic_almaPipeline)
sdf_LinearRegressionPipeline = sdf_TrumpApproval.apply(LinearRegressionPipeline.train_and_predict).to_topic(output_topic_LinearRegressionPipeline)


# ---------- DASHBOARD SETUP ----------

def run_dash():
    dash_app = Dash(__name__)
    dash_app.layout = html.Div([
         html.H2("Pipelines' Plots" , style={
        'textAlign': 'center',  # Center the text

        'fontFamily': 'sans-serif',  # Change the font family
        'font-weight': 'normal',  # Make the text bold
        }),
        dcc.Interval(id='interval', n_intervals=0),
        dcc.Graph(id='live-graph'), 
        html.Div(
            children=[
                dcc.Graph(
                    id='live-stats',
                    style={'margin': 'auto', 'display': 'block', 'width':'70%'}
                )
            ]
        )
    ])

    @dash_app.callback(
        Output('live-graph', 'figure'),
        Input('interval', 'n_intervals')
    )
    def update_graph(n):
        fig = make_subplots(rows=2, cols=1 , vertical_spacing=0.1)

        
        almaPipeline.add_metrics_traces(fig = fig , row = 1, col = 1 ) 
        
        LinearRegressionPipeline.add_metrics_traces(fig = fig , row = 2, col = 1 ) 
        

        fig.update_layout(height=600, title="Live Metrics", margin=dict(t=40, b=40), showlegend=True )
        return fig

    @dash_app.callback(
        Output(
            component_id='live-stats', 
            component_property='figure'
        ), 
        Input(
            component_id='interval', 
            component_property='n_intervals'
        )
    )    
    def update_stats(n):
        
        traces = []  
        
        almaPipeline.add_stats_traces(traces) 
        
        LinearRegressionPipeline.add_stats_traces(traces) 
               

        
        if traces:
            fig = go.Figure(
                    data=traces, 
                    layout= go.Layout(
                        title='Statistics'
                    )
            )
            return fig    
    
        return go.Figure()
    
    dash_app.run(debug=True, use_reloader=False)

if __name__ == '__main__':
    #Run Plotly on different thread
    threading.Thread(target=run_dash, daemon=True).start()
   
    # Run Quix Streams 
    app.run()